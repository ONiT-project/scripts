{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62e8e6a6",
   "metadata": {},
   "source": [
    "## Create List of Images Exported with Illustration Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e99998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "def get_file_names(root_folder, extension='.jpg'):\n",
    "    file_list = []\n",
    "    for folder, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(extension):\n",
    "                file_path = os.path.join(folder[-36:], file)\n",
    "                barcode = os.path.basename(folder)\n",
    "                tag = os.path.basename(os.path.dirname(folder))\n",
    "                file_list.append({'filename': file, 'path': file_path, 'barcode': barcode, 'lang_year': tag})\n",
    "    return file_list\n",
    "\n",
    "# Replace 'your_root_folder' with the path to your top-level directory\n",
    "root_folder = 'your_root_folder'\n",
    "file_list = get_file_names(root_folder)\n",
    "\n",
    "# Create a DataFrame from the file list\n",
    "df_files = pd.DataFrame(file_list)\n",
    "\n",
    "# Display the DataFrame\n",
    "df_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c512024",
   "metadata": {},
   "source": [
    "## Import Discarded Images from ONiT Similarity Explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df19394",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_all_filenames(json_path):\n",
    "    all_filenames = []\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for key, filenames in data.items():\n",
    "            all_filenames.extend([filename + '.jpg' for filename in filenames])\n",
    "    return all_filenames\n",
    "\n",
    "# Example usage\n",
    "json_path = 'your_json_path/discardedImages20230312.json'\n",
    "discarded_files_new = get_all_filenames(json_path)\n",
    "\n",
    "print(len(discarded_files_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d61c51b",
   "metadata": {},
   "source": [
    "## Remove Discarded Images from Full List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80803b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove discarded files from loaded list with inverted mask (negated .isin() condition)\n",
    "images_cleaned = df_files[~df_files['filename'].isin(discarded_files_new)]\n",
    "\n",
    "print(len(images_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb61f4",
   "metadata": {},
   "source": [
    "## Import Barcodes from Metadata Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2bc6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import barcodes from metadata lists\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def get_barcodes(path):\n",
    "    barcodes = []\n",
    "    long_bc_count = 0\n",
    "    \n",
    "    for folder, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            print('Processing ', file)\n",
    "            file_path = os.path.join(path, file)\n",
    "            #print(file_path)\n",
    "            corpus = file[11:14]\n",
    "            with open(file_path,'rb') as f:\n",
    "                data = pd.read_excel(f)\n",
    "                for barcode in data['Barcode']:\n",
    "                    if not pd.isna(barcode):\n",
    "                        if len(str(barcode)) > 10:\n",
    "                            long_bc_count += 1\n",
    "                            #print(f'Barcode > 10char: ', barcode)\n",
    "                        shortened_barcode = barcode[:10] # add only first barcode to remove duplicates (exception: journals - not included here)\n",
    "                        barcodes.append({'barcode': shortened_barcode, 'corpus': corpus})\n",
    "        print(f'Number of barcodes > 10char: ', long_bc_count)\n",
    "        return barcodes\n",
    "\n",
    "path = 'path_to_folder'\n",
    "filenames = get_barcodes(path)\n",
    "\n",
    "barcodes = pd.DataFrame(filenames)\n",
    "\n",
    "barcodes.to_csv('ONiT_barcodes_full-list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fbe919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove barcode entries from cleaned list that are not present in the full barcodes list\n",
    "## Note: multiple barcodes per entry are removed; a list of journal barcodes is missing here\n",
    "images_cleaned_new = images_cleaned[images_cleaned['barcode'].isin(barcodesNew['barcode'])]\n",
    "\n",
    "print(len(images_cleaned_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6081290b",
   "metadata": {},
   "source": [
    "## Create JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33216b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "read_file = pd.read_csv(r'ONiT_extracted-images_full.csv')[['filename','barcode','iiif', 'lang_year']]\n",
    "\n",
    "# Create local_url column & adapt entries & structure\n",
    "#read_file['local_url'] = 'http://localhost/images/' + read_file['barcode'] + '/' + read_file['filename']\n",
    "read_file['filename'] = read_file['filename'].str.replace(\".jpg\",\"\", regex=True)\n",
    "#read_file = read_file.drop('barcode', axis=1)\n",
    "reorder = ['filename', 'barcode', 'iiif', 'lang_year']\n",
    "read_file = read_file[reorder]\n",
    "read_file = read_file.rename(columns={'filename': 'id', 'iiif': 'iiif_url', 'lang_year': 'corpus'})\n",
    "\n",
    "# Convert to dictionary\n",
    "neighbors_data = read_file[['id', 'barcode', 'iiif_url', 'corpus']].to_dict(orient='records')\n",
    "\n",
    "# Write dictionary to a JSON file\n",
    "output_file_path = 'your_output_file_path.json'\n",
    "\n",
    "with open(output_file_path, 'w') as json_file:\n",
    "    json.dump(neighbors_data, json_file, indent=2)\n",
    "\n",
    "print(f\"JSON file created at: {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e76965",
   "metadata": {},
   "source": [
    "## Copy JPGs of Curated Collection to New Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cac5ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files(source_folder, destination_folder, filenames):\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "        print(f\"Created folder: '{destination_folder}'\")\n",
    "        \n",
    "    for folder, _, files in os.walk(source_folder):\n",
    "        for filename in filenames:\n",
    "            source_path = os.path.join(folder, filename)\n",
    "            destination_path = os.path.join(destination_folder, filename)\n",
    "            try:\n",
    "                shutil.copy2(source_path, destination_path)\n",
    "                print(f\"File '{filename}' copied to '{destination_folder}'\")\n",
    "            except FileNotFoundError:\n",
    "                pass  # Skip to the next file if it's not found\n",
    "\n",
    "# Example usage:\n",
    "source_folder = 'your_source_folder'\n",
    "destination_folder = 'your_target_folder'\n",
    "filenames = images_cleaned_new['filename'].to_list()\n",
    "\n",
    "#filenames\n",
    "copy_files(source_folder, destination_folder, filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851ed1e2",
   "metadata": {},
   "source": [
    "## Data Analysis & Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686983fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Count images per language & century\n",
    "lang_order = images_cleaned_new['lang_year'].unique()\n",
    "lang_year_counts = images_cleaned_new['lang_year'].value_counts().loc[lang_order]\n",
    "\n",
    "# Create a bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(lang_year_counts.index, lang_year_counts.values)\n",
    "\n",
    "# Customize the plot if needed\n",
    "plt.title('Number of Images with Nature Representations per Sub-Corpus')\n",
    "plt.xlabel('Sub-Corpus (Language/Century)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924071bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'barcode' and 'lang_year', then count the number of files in each group\n",
    "grouped_df = images_cleaned_new.groupby(['barcode', 'lang_year']).size().reset_index(name='file_count')\n",
    "\n",
    "# Reorder the groups based on the order of unique 'lang_year' values\n",
    "grouped_df['lang_year'] = pd.Categorical(grouped_df['lang_year'], categories=lang_order, ordered=True)\n",
    "grouped_df = grouped_df.sort_values(by=['lang_year'])\n",
    "\n",
    "# Create a bar chart using Matplotlib with Axes object\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Iterate over unique 'lang_year' values and plot bars for each\n",
    "for lang_year in lang_order:\n",
    "    subset_df = grouped_df[grouped_df['lang_year'] == lang_year]\n",
    "    ax.bar(subset_df['barcode'], subset_df['file_count'], label=str(lang_year))\n",
    "\n",
    "# Hide x-axis labels (barcodes)\n",
    "ax.set_xticks([])\n",
    "\n",
    "# Customize the plot if needed\n",
    "ax.set_title('Number of Images per Barcode, Ordered by Language/Century')\n",
    "ax.set_ylabel('File Count')\n",
    "ax.legend(title='language/century')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7705c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'lang_year' and calculate the number of files and unique barcodes\n",
    "grouped_2 = images_cleaned_new.groupby('lang_year').agg({'filename': 'count', 'barcode': 'nunique'}).reset_index()\n",
    "\n",
    "# Create a grouped bar chart using Matplotlib\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Bar positions\n",
    "bar_width = 0.45\n",
    "bar_positions_files = grouped_2.index\n",
    "bar_positions_barcodes = [pos + bar_width for pos in bar_positions_files]\n",
    "\n",
    "# Plot bars for files\n",
    "files_bars = ax.bar(bar_positions_files, grouped_2['filename'], width=bar_width, label='Images')\n",
    "\n",
    "# Plot bars for unique barcodes\n",
    "barcodes_bars = ax.bar(bar_positions_barcodes, grouped_2['barcode'], width=bar_width, label='Unique Barcodes')\n",
    "\n",
    "# Display the sum of barcodes and images next to the bars\n",
    "for bar, value in zip(files_bars, grouped_2['filename']):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "            f'{value}', ha='center', va='bottom')\n",
    "\n",
    "for bar, value in zip(barcodes_bars, grouped_2['barcode']):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "            f'{value}', ha='center', va='bottom')\n",
    "\n",
    "# Customize the plot\n",
    "ax.set_xticks([pos + bar_width/2 for pos in bar_positions_files])\n",
    "ax.set_xticklabels(grouped_2['lang_year'])\n",
    "ax.set_title('Number of Images and Unique Barcodes per Language/Century')\n",
    "ax.set_xlabel('Language/Century')\n",
    "ax.set_ylabel('Count')\n",
    "ax.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
